{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d51b419-78de-406b-8c55-f061cd4b9eed",
   "metadata": {},
   "source": [
    "# Lab No 2: Data Manipulation and Working with Web Services\n",
    "\n",
    "## 2 Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b6050-b4cc-46f8-8258-e6028b933bd2",
   "metadata": {},
   "source": [
    "# Challenge No 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5f6c4-d24c-4ab9-82b8-6c4fd5e95fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code for challenge 1, Lab 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a66bf29-8b8f-4331-8c17-be365e6895c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Using a Dictionary, create a dataframe (table), with at least 4 columns and more than 100 rows. How come you can create this among data from scratch without defining every single row of data?\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "num_rows = 150\n",
    "\n",
    "data = {\n",
    "    'Bromley': np.random.randint(5, 30, num_rows),\n",
    "    'Croydon': np.random.randint(5, 30, num_rows),\n",
    "    'Dagenham': np.random.randint(5, 30, num_rows),\n",
    "    'Lewisham': np.random.randint(5, 30, num_rows)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c568ad-a78e-45a3-a2ac-102398cea3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df.iloc[:30, :3]\n",
    "print(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3effe121-0e1e-4334-b0a4-62262acebddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = subset_df.loc[(subset_df > 10).all(axis=1)]\n",
    "filtered_C_df = filtered_df.loc[:,'Croydon']\n",
    "\n",
    "print(filtered_C_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d888fdd-363a-4620-a709-a23e4aab89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the mean\n",
    "filtered_C_df.mean(axis=0, skipna=True, numeric_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd87d681-1a83-4338-a2f4-7bfae0ad351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying standard deviation\n",
    "filtered_C_df.std(axis=0, skipna=True, ddof=1, numeric_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc133f-79d1-4af8-b8aa-f7234249e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying group_by \n",
    "grouped_df = df.groupby(['Bromley']).mean()\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c1433-bb38-4630-a13f-ff24fddc47b4",
   "metadata": {},
   "source": [
    "# Challenge No 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022bf66-bdac-443a-b429-5465a0b8e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code for challenge 2, Lab 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdedc7-8623-4baa-9dca-d785a783ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Let's describe the url, it is usually easier to do it like this, so in the future, you can easily update the URL\n",
    "url_bikes = \"https://api.glasgow.gov.uk/mobility/v1/get_rentals?startDate=2022-05-01&endDate=2023-05-01\"\n",
    "# Making the query to the web server, using the Get method from the requests library \n",
    "response = requests.get(url_bikes)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d198956c-a77f-4f0f-b7df-88b38088b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we get the response from the web server, we need to translate that into a format we can manipulate, like JSON.\n",
    "data = response.json()\n",
    "data\n",
    "# careful here you will get a huge outcome; explore what you get, and then you can clear this cell outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee6542-cc0a-441a-9cca-cbe6ec305ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually, there are two labels into the web server response the metadata, and the data; we will use the data label\n",
    "# to get all attributes included. \n",
    "rental_data = data['data']\n",
    "rental_data\n",
    "# See the structure of the data, you can see\n",
    "# 'attribute':'value' structure\n",
    "# each {} define one row or one element\n",
    "# Again, here you will get a huge outcome; just explore what you get, and then you can clear this cell outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef62be-bcb9-49e7-821d-2ce5f0a53cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_pd = pd.DataFrame(rental_data)\n",
    "rental_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220bfa9-829f-47b8-a50d-96e34ab0ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131f064-e806-4af0-857f-4e61f5b4c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21f8d7-0db4-4dd6-a1f6-54cfb3e223f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN in the coordinates column\n",
    "nan_in_column_Lat = rental_pd['startPlaceLat'].isna().any()\n",
    "nan_in_column_Long = rental_pd['startPlaceLong'].isna().any()\n",
    "\n",
    "print(nan_in_column_Lat,nan_in_column_Lat)\n",
    "\n",
    "# Alternatively, you can use the following to count NaN values\n",
    "nan_in_column_Lat = rental_pd['startPlaceLat'].isna().sum()\n",
    "nan_in_column_Long = rental_pd['startPlaceLong'].isna().sum()\n",
    "print(nan_in_column_Lat,nan_in_column_Lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed673700-e6f8-4b3c-bed0-15c2b9bfaa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rental_pd = rental_pd.dropna(subset=['startPlaceLat', 'startPlaceLong', 'endPlaceLat','endPlaceLong'])\n",
    "clean_rental_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b7649-4116-4664-a81f-d6e4dfd994cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start = gpd.GeoDataFrame(clean_rental_pd, geometry=gpd.points_from_xy(clean_rental_pd['startPlaceLong'], clean_rental_pd['startPlaceLat']))\n",
    "gdf_bikes_end = gpd.GeoDataFrame(clean_rental_pd, geometry=gpd.points_from_xy(clean_rental_pd['endPlaceLong'], clean_rental_pd['endPlaceLat']))\n",
    "\n",
    "# Print the GeoDataFrame\n",
    "gdf_bikes_start.info()\n",
    "# Do we need all those columns? And you see, there is also a lot of pre-processing to do with all the object Dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947c799-3cee-49a9-8952-799848216002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the geodataframe's data types and attributes\n",
    "gdf_bikes_end.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61428b9-19ef-42c1-bbe4-e7534015fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the geodataframe\n",
    "gdf_bikes_end.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8b7bd-2f1c-48e4-a107-78bcab67d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping null values within the subsets start place latitude and longitude\n",
    "gdf_bikes_end = gdf_bikes_end.dropna(subset=['startPlaceLat', 'startPlaceLong'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1b91c-8955-4941-8d7a-df303e31f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the coordinate reference system for the geodataframe\n",
    "gdf_bikes_end = gdf_bikes_end.set_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0005e3-98a3-4a9c-b1d8-16fc2db258ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping columns and cleaning up the dataset\n",
    "keep_cols = [\n",
    "    \"startDate\",\n",
    "    \"startPlaceId\",\n",
    "    \"startPlaceName\",\n",
    "    \"durationSeconds\",\n",
    "    \"isInvalid\",\n",
    "    \"price\",\n",
    "    \"isEbike\",\n",
    "    \"startPlaceLat\",\n",
    "    \"startPlaceLong\",\n",
    "    \"geometry\",\n",
    "]\n",
    "gdf_bikes_end = gdf_bikes_end[keep_cols]\n",
    "gdf_bikes_end.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f3694-c628-4ca5-b3c6-f286ccc1bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now checking how attributes have changed\n",
    "gdf_bikes_end.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9116f93a-d0b6-49fd-8528-a31d30433d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping the data types within the geodataframe consistent\n",
    "gdf_bikes_end.startPlaceId = gdf_bikes_end.startPlaceId.astype(int)\n",
    "gdf_bikes_end.startPlaceName = gdf_bikes_end.startPlaceName.astype(str)\n",
    "gdf_bikes_end['startDate'] = pd.to_datetime(gdf_bikes_end['startDate'], format='%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda270c3-60a4-4b00-87e4-f3d612ac8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking that the data type consolidation was successful\n",
    "gdf_bikes_end.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba23da9-7256-4dbb-9bd0-3b375c1218da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the first few rows of the dataset\n",
    "gdf_bikes_end.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15af36d-6929-4e7e-bd50-26cb3c4e5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing leafmap in order to generate a map of the geodataframe\n",
    "import leafmap\n",
    "\n",
    "m = leafmap.Map(center=(55.860166, -4.257505),\n",
    "                zoom=12,\n",
    "                draw_control=False,\n",
    "                measure_control=False,\n",
    "                fullscreen_control=False,\n",
    "                attribution_control=True,\n",
    "                   \n",
    "               )\n",
    "\n",
    "m.add_basemap(\"CartoDB.Positron\")\n",
    "m.add_data(\n",
    "    gdf_bikes_end,\n",
    "    column='startPlaceName',\n",
    "    legend_title='Clusters',\n",
    "    cmap='Set1',\n",
    "    k=4,\n",
    ")\n",
    "\n",
    "#Ploting the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab485f7-13be-4996-940f-2ad50d612f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for part 2 of the challenge, I will describe the url of our data source and use requests to make the query to the web server\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "url_sensor = \"https://api.glasgow.gov.uk/traffic/v1/movement/sites?null=3_weeks_ago HTTP/1.1\"\n",
    "response = requests.get(url_sensor)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29326b22-2123-4982-b9a2-a19ea147de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data = response.json()\n",
    "sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ccd54-569e-4d8f-81c0-429360447d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sensor_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d0d4a-183f-491a-955d-2f434091943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference for using Point: Readthedocs.io. (2024). shapely.Point — Shapely 2.0.6 documentation. [online] Available at: https://shapely.readthedocs.io/en/2.0.6/reference/shapely.Point.html.\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01138e5d-b805-4d8f-96d6-952ea1e79e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making siteId an integer\n",
    "for sensor in sensor_data:\n",
    "    sensor[\"siteId\"] = int(sensor[\"siteId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa0da3-e4b7-424c-bccb-593ece918a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing siteId\n",
    "df_zones[\"siteId\"] = pd.to_numeric(df_zones[\"siteId\"], errors=\"coerce\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb845f-eaa1-4264-9088-ca88308040a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#focusing on siteIds - extracting locations of sensors for the dataframe\n",
    "sensor_list = sensor_data[\"siteId\"]\n",
    "df_sensors = pd.DataFrame(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384e301-5271-4f85-bcaa-3a1401179606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the json to a dataframe\n",
    "gdf_sensors = gpd.GeoDataFrame(\n",
    "    df_sensors, geometry=gpd.points_from_xy(df_sensors['lon'], df_sensors['lat'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4daf4-033c-4536-ba61-514005ac069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting our CRS to the Geodetic coordinate system\n",
    "gdf_sensors.set_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3612c4b-9fcf-4261-9978-6a109ce59231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the first few rows of data\n",
    "print(gdf_sensors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfe134-d090-486a-bd36-3fbd275c1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeating process for working zones from API URL for Glasgow\n",
    "url_zones = \"https://api.glasgow.gov.uk/traffic/v1/working_zones\"\n",
    "\n",
    "#fetching the data\n",
    "response_zones = requests.get(url_zones)\n",
    "response_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bce7a1-e3ad-48ba-aac3-340d9a9fd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_data = response.json()\n",
    "zones_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd04a12-8a8c-4b38-9d4d-aab0211c3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference for using Point: Readthedocs.io. (2024). shapely.Point — Shapely 2.0.6 documentation. [online] Available at: https://shapely.readthedocs.io/en/2.0.6/reference/shapely.Point.html.\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d7105-f51d-4b1f-a933-314bc3bd675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making siteId an integer\n",
    "for zones in zones_data:\n",
    "    zones[\"siteId\"] = int(zones[\"siteId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef5b2b-07cb-4338-8102-1b8953c54c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting into dataframe\n",
    "df_zones = pd.DataFrame(zones_data[\"siteId\"])  \n",
    "df_zones[\"geometry\"] = df_zones[\"polygon\"].apply(lambda x: Polygon(x)) \n",
    "\n",
    "#setting crs and geometry\n",
    "gdf_zones = gpd.GeoDataFrame(df_zones, geometry=\"geometry\")\n",
    "gdf_zones.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "#exploring the first few rows of data\n",
    "print(gdf_zones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b6d21-54fe-4e15-8da2-2748e2754562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing spatial joins using sjoin\n",
    "gdf_sensors_zones = gpd.sjoin(gdf_sensors, gdf_zones, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "#exploring the first few rows\n",
    "print(gdf_sensors_zones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf085c5-588b-4904-bca9-a331739473f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting the sensors in every working zone\n",
    "sensor_counts = gdf_sensors_zones.groupby(\"zone_id\").size().reset_index(name=\"sensor_count\")\n",
    "\n",
    "#merging the counts into the working zone geodataframe\n",
    "gdf_zones = gdf_zones.merge(sensor_counts, on=\"zone_id\", how=\"left\")\n",
    "\n",
    "#getting rid of non values\n",
    "gdf_zones[\"sensor_count\"] = gdf_zones[\"sensor_count\"].dropna()\n",
    "\n",
    "print(gdf_zones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c35b1-eabb-490d-9a88-8220e72a6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the chloropleth map using leafmap\n",
    "import leafmap\n",
    "\n",
    "m = leafmap.Map(\n",
    "    center=(56.329031,-3.798943),\n",
    "    zoom=7\n",
    ")\n",
    "\n",
    "m.add_basemap(\"CartoDB.Positron\")\n",
    "\n",
    "m.add_data(\n",
    "    gdf_zones,\n",
    "    column=\"sensor_count\",\n",
    "    legend_title=\"Sensor Count\",\n",
    "    cmap=\"OrRd\",  # Red color gradient (adjust if needed)\n",
    "    k=5,  # Number of color bins\n",
    ")\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2ca95c-8cf1-4955-bbf3-aac3ff55c120",
   "metadata": {},
   "source": [
    "# GG4257 - Urban Analytics: A Toolkit for Sustainable Urban Development\n",
    "## Lab Workbook No 2: Data Manipulation and Working with Web Services\n",
    "## CHALLENGE 2\n",
    "---\n",
    "Dr Fernando Benitez -  University of St Andrews - School of Geography and Sustainable Development - Iteration 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ce7b8-96b5-4aef-b9c1-b9ae4e5e8027",
   "metadata": {},
   "source": [
    "In the following example, we will use the Glasglow Open Data API to fetch data from the bike rentals.\n",
    "1. Please go to https://developer.glasgow.gov.uk/\n",
    "2. Sign Up and explore the available APIs\n",
    "3. Go to https://developer.glasgow.gov.uk/api-details#api=mobility&operation=get-getrentals and explore the available parameters to fetch data from the Bike Rentals in Glasgow.\n",
    "4. To your right, you will see a tiny green button, **Try it**, where you can play with the API requests and see if you can get an appropriate response for the last 3 weeks of data. Help: Just add the parameter `3_weeks_ago` in the Value box and then click on the **Send** button to see how the API responds. This is what we will apply but using python to write some analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63bd35e-d5d7-48f3-a45a-7e51b0a67bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Let's describe the url, it is usually easier to do it like this, so in the future, you can easily update the URL\n",
    "url_bikes = \"https://api.glasgow.gov.uk/mobility/v1/get_rentals?startDate=2022-05-01&endDate=2023-05-01\"\n",
    "# Making the query to the web server, using the Get method from the requests library \n",
    "response = requests.get(url_bikes)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b482549-7b47-4a10-9190-01eb4e43a37f",
   "metadata": {},
   "source": [
    "You see the response has a 200 code, which means the request as satisfactory, here the possible other codes you can get and hence you can see if your code has any issue. https://www.w3schools.com/tags/ref_httpmessages.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566069e-989d-46d5-b6ed-cd5b2c759142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we get the response from the web server, we need to translate that into a format we can manipulate, like JSON.\n",
    "data = response.json()\n",
    "data\n",
    "# careful here you will get a huge outcome; explore what you get, and then you can clear this cell outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700af0f-7f0b-4919-be4d-f32d67d8f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually, there are two labels into the web server response the metadata, and the data; we will use the data label\n",
    "# to get all attributes included. \n",
    "rental_data = data['data']\n",
    "rental_data\n",
    "# See the structure of the data, you can see\n",
    "# 'attribute':'value' structure\n",
    "# each {} define one row or one element\n",
    "# Again, here you will get a huge outcome; just explore what you get, and then you can clear this cell outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c835181-dffc-4c1a-bb26-38e6f37e383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_pd = pd.DataFrame(rental_data)\n",
    "#Can you guess what we are doing here?\n",
    "rental_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df5733-4ba1-4e58-9d29-82ac0ad08522",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6b605-05e7-4638-97fa-28720720a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e9544-2e85-44b0-9414-55d83e9a60a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN in the coordinates column\n",
    "nan_in_column_Lat = rental_pd['startPlaceLat'].isna().any()\n",
    "nan_in_column_Long = rental_pd['startPlaceLong'].isna().any()\n",
    "\n",
    "print(nan_in_column_Lat,nan_in_column_Lat)\n",
    "\n",
    "# Alternatively, you can use the following to count NaN values\n",
    "nan_in_column_Lat = rental_pd['startPlaceLat'].isna().sum()\n",
    "nan_in_column_Long = rental_pd['startPlaceLong'].isna().sum()\n",
    "print(nan_in_column_Lat,nan_in_column_Lat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9454c01-5567-4af7-9ab0-3d79fdaa90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rental_pd = rental_pd.dropna(subset=['startPlaceLat', 'startPlaceLong', 'endPlaceLat','endPlaceLong'])\n",
    "clean_rental_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d8b25-d787-4964-b7cd-6ca860215b90",
   "metadata": {},
   "source": [
    "Now, using the GeoPandas Documentation site, we can see how to build a Geodataframe using the Lat and Long attributes. This dataset includes two sets of coordinates, one for when the user gets the bike and another one for when the user returns the bike. \n",
    "\n",
    "https://geopandas.org/en/stable/gallery/create_geopandas_from_pandas.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f8e77-5822-42c6-a014-2ae098db7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start = gpd.GeoDataFrame(clean_rental_pd, geometry=gpd.points_from_xy(clean_rental_pd['startPlaceLong'], clean_rental_pd['startPlaceLat']))\n",
    "gdf_bikes_end = gpd.GeoDataFrame(clean_rental_pd, geometry=gpd.points_from_xy(clean_rental_pd['endPlaceLong'], clean_rental_pd['endPlaceLat']))\n",
    "\n",
    "# Print the GeoDataFrame\n",
    "gdf_bikes_start.info()\n",
    "# Do we need all those columns? And you see, there is also a lot of pre-processing to do with all the object Dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d06b52-00f0-4d37-b4a9-d7163a19bcbb",
   "metadata": {},
   "source": [
    "Let's plot one of the GeoPandasDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefccecd-7f76-4112-a96d-b3ec9bf878fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa8d9e0-81cf-4728-b6bf-6b1708027118",
   "metadata": {},
   "source": [
    "What is wrong with the previous map? why the points arent well located? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4f92a-9e4a-4795-8d5a-ae33a86e5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cabbc82-c2a8-4741-83af-8db610ebd310",
   "metadata": {},
   "source": [
    "You see what the problem is?, let me fix that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac904160-be26-48ab-801d-86f1ca9439e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start = gdf_bikes_start.set_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea69aa-dc71-433b-8c84-222ae0aa228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b97aa-d15f-4d3a-90ae-d3665be84383",
   "metadata": {},
   "source": [
    "You could have fixed that problem from the moment you created the GeoPandasDataFrame, just follow the example included in the documentation link: https://geopandas.org/en/stable/gallery/create_geopandas_from_pandas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2748cc8-5062-419f-9ee8-75b9edc86e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03741760-a859-4c8c-8213-e0b57fc26912",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\n",
    "    \"startDate\",\n",
    "    \"startPlaceId\",\n",
    "    \"startPlaceName\",\n",
    "    \"durationSeconds\",\n",
    "    \"isInvalid\",\n",
    "    \"price\",\n",
    "    \"isEbike\",\n",
    "    \"startPlaceLat\",\n",
    "    \"startPlaceLong\",\n",
    "    \"geometry\",\n",
    "]\n",
    "gdf_bikes_start = gdf_bikes_start[keep_cols]\n",
    "gdf_bikes_start.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc1bab-5d2f-46c5-bf6f-07e3d6745398",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ca3f6-b469-4637-8917-dc0a3c4e7b1b",
   "metadata": {},
   "source": [
    "Updating the requiered and more appropiated Dtypes for the remainng columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04667ce3-a8e8-4400-ac0e-aa398707e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start.startPlaceId = gdf_bikes_start.startPlaceId.astype(int)\n",
    "gdf_bikes_start.startPlaceName = gdf_bikes_start.startPlaceName.astype(str)\n",
    "gdf_bikes_start['startDate'] = pd.to_datetime(gdf_bikes_start['startDate'], format='%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbedeae4-6281-4982-959e-79e5fc412bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start.dtypes\n",
    "#gdf_bikes_start['startPlaceName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d35e88-9870-46ab-8de1-9542e6f3998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2d2ae-9970-488f-8640-01167d37249f",
   "metadata": {},
   "source": [
    "Now, we want to see where the more dense areas are and where the bikes get collected so that we will use a simple but straightforward cluster analysis. We will explore this in more detail later in this course; for now, let's apply an ML library in Python sklearn (https://scikit-learn.org/stable/index.html) and define only 4 cluster areas. We will use the geometry attribute to get our Lat and Long values, which are required for the sklearn library fit_predict method.\n",
    "\n",
    "Before that, let's explore how we get the Lat and the Long values in the way the cluster method requires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673af6fe-c762-4366-9f3b-0430cbe3b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 4\n",
    "\n",
    "kmeans_collection = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "gdf_bikes_start['kmeans_cluster'] = kmeans_collection.fit_predict(gdf_bikes_start[['startPlaceLong', 'startPlaceLat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51126c-2130-4b03-8e89-eb94f11c726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bikes_start.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167f84a-fbd3-48e6-a8b4-8a4bf5e2d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mport leafmap\n",
    "\n",
    "m = leafmap.Map(center=(55.860166, -4.257505),\n",
    "                zoom=12,\n",
    "                draw_control=False,\n",
    "                measure_control=False,\n",
    "                fullscreen_control=False,\n",
    "                attribution_control=True,\n",
    "                   \n",
    "               )\n",
    "\n",
    "m.add_basemap(\"CartoDB.Positron\")\n",
    "m.add_data(\n",
    "    gdf_bikes_start,\n",
    "    column='kmeans_cluster',\n",
    "    legend_title='Clusters',\n",
    "    cmap='Set1',\n",
    "    k=4,\n",
    ")\n",
    "\n",
    "#Ploting the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d21e11-c8ab-4c72-86f0-977a3960ce17",
   "metadata": {},
   "source": [
    "# Challenge No 2:\n",
    "\n",
    "**Part No 1:**\n",
    "\n",
    "1. Using the same workflow previously described, now calculate the clustered areas for the GeoPandasDataFrame `gdf_bikes_end`\n",
    "2. Make sure you don't have any NaN in your columns, add a CRS, clean up the unnecessary attributes, calculate the cluster values, and plot a map of 4 calculated clusters for the return locations.\n",
    "\n",
    "**Part No 2:**\n",
    "\n",
    "1. Using the Glasglow Open Data API ( Transit) https://developer.glasgow.gov.uk/api-details#api=traffic&operation=traffic-sensor-locations fetch all the sensor locations in the city.\n",
    "2. Map the sensor\n",
    "3. Find the WorkingZones and Calculate/Map the areas with more and fewer sensors distributed in the city.\n",
    "4. You will need:\n",
    "   * Get two separate Geopandas DataFrames, one for the traffic sensors and another one for the WorkingZones.\n",
    "   * Using `sJoin` ( Spatial Join) https://geopandas.org/en/stable/docs/reference/api/geopandas.sjoin.html\n",
    "   calculate the overlay of sensors and polygons.\n",
    "   * Using group_by https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html to count the number of sensors per WorkingZone\n",
    "   * Make sure you add the counts into the WorkingZone polygons of Glasgow so you can create a map of Zones with more and fewer traffic sensors.\n",
    "   * Of course, you will need extra steps where you manipulate the data and extract what you need, for instance, clipping the Working Zones only for Glasgow.\n",
    "5. Make sure you comment on your code and describe how you are manipulating the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f2a59-0ce1-403e-8d04-ea9e95420bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the geodataframe's data types and attributes\n",
    "gdf_bikes_end.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a02261-213f-4079-b8ec-c3b2746ff5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the geodataframe\n",
    "gdf_bikes_end.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569fddf-a510-40d9-92e5-f278e2ea7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping null values within the subsets start place latitude and longitude\n",
    "gdf_bikes_end = gdf_bikes_end.dropna(subset=['startPlaceLat', 'startPlaceLong'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b321e-c29a-427e-9d1e-fcb482e6aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the coordinate reference system for the geodataframe\n",
    "gdf_bikes_end = gdf_bikes_end.set_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2275984-9664-4a56-bf2f-09071d31f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping columns and cleaning up the dataset\n",
    "keep_cols = [\n",
    "    \"startDate\",\n",
    "    \"startPlaceId\",\n",
    "    \"startPlaceName\",\n",
    "    \"durationSeconds\",\n",
    "    \"isInvalid\",\n",
    "    \"price\",\n",
    "    \"isEbike\",\n",
    "    \"startPlaceLat\",\n",
    "    \"startPlaceLong\",\n",
    "    \"geometry\",\n",
    "]\n",
    "gdf_bikes_end = gdf_bikes_end[keep_cols]\n",
    "gdf_bikes_end.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185bf620-80c3-4075-a3bb-9b1a0b690fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now checking how attributes have changed\n",
    "gdf_bikes_end.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d15a6-dee9-4875-ab4c-0d730ba90609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping the data types within the geodataframe consistent\n",
    "gdf_bikes_end.startPlaceId = gdf_bikes_end.startPlaceId.astype(int)\n",
    "gdf_bikes_end.startPlaceName = gdf_bikes_end.startPlaceName.astype(str)\n",
    "gdf_bikes_end['startDate'] = pd.to_datetime(gdf_bikes_end['startDate'], format='%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6a385-3cb5-42bc-909e-ba6b2f9d90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking that the data type consolidation was successful\n",
    "gdf_bikes_end.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536d275-3248-40a1-b39d-360c8d81335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the first few rows of the dataset\n",
    "gdf_bikes_end.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48fba3-a914-4d84-908c-06acd0950a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing leafmap in order to generate a map of the geodataframe\n",
    "import leafmap\n",
    "\n",
    "m = leafmap.Map(center=(55.860166, -4.257505),\n",
    "                zoom=12,\n",
    "                draw_control=False,\n",
    "                measure_control=False,\n",
    "                fullscreen_control=False,\n",
    "                attribution_control=True,\n",
    "                   \n",
    "               )\n",
    "\n",
    "m.add_basemap(\"CartoDB.Positron\")\n",
    "m.add_data(\n",
    "    gdf_bikes_end,\n",
    "    column='startPlaceName',\n",
    "    legend_title='Clusters',\n",
    "    cmap='Set1',\n",
    "    k=4,\n",
    ")\n",
    "\n",
    "#Ploting the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d2f05-7a13-462b-aaa8-d3ee231d15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for part 2 of the challenge, I will describe the url of our data source and use requests to make the query to the web server\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "url_sensor = \"https://api.glasgow.gov.uk/traffic/v1/movement/sites?null=3_weeks_ago HTTP/1.1\"\n",
    "response = requests.get(url_sensor)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68fcdd-2b66-4f09-ba33-26bda3c1b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data = response.json()\n",
    "sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874b86a-f414-4f57-8196-3756fc9d6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sensor_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d087f-a105-433c-8ab8-19c6cba31496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference for using Point: Readthedocs.io. (2024). shapely.Point — Shapely 2.0.6 documentation. [online] Available at: https://shapely.readthedocs.io/en/2.0.6/reference/shapely.Point.html.\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6978d-9986-4e56-9ae7-040b22148cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making siteId an integer\n",
    "for sensor in sensor_data:\n",
    "    sensor[\"siteId\"] = int(sensor[\"siteId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce0a4b-3d75-48a1-ad34-f921a5d7c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing siteId\n",
    "df_zones[\"siteId\"] = pd.to_numeric(df_zones[\"siteId\"], errors=\"coerce\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3094af-3672-47df-9f14-661bf0441bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#focusing on siteIds - extracting locations of sensors for the dataframe\n",
    "sensor_list = sensor_data[\"siteId\"]\n",
    "df_sensors = pd.DataFrame(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a5d94-cf98-46ac-bc2c-df88663764fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the json to a dataframe\n",
    "gdf_sensors = gpd.GeoDataFrame(\n",
    "    df_sensors, geometry=gpd.points_from_xy(df_sensors['lon'], df_sensors['lat'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a851593-fed8-4e36-993c-86af40eb5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting our CRS to the Geodetic coordinate system\n",
    "gdf_sensors.set_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8a917-98ff-41bf-bd2c-0d3e2d26e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the first few rows of data\n",
    "print(gdf_sensors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889b8107-b20c-4839-914f-c1af3f253743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeating process for working zones from API URL for Glasgow\n",
    "url_zones = \"https://api.glasgow.gov.uk/traffic/v1/working_zones\"\n",
    "\n",
    "#fetching the data\n",
    "response_zones = requests.get(url_zones)\n",
    "response_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352f6460-1540-4305-8926-47782f9ce0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_data = response.json()\n",
    "zones_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a8956-14be-471b-a0e4-65c4d85fd340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference for using Point: Readthedocs.io. (2024). shapely.Point — Shapely 2.0.6 documentation. [online] Available at: https://shapely.readthedocs.io/en/2.0.6/reference/shapely.Point.html.\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da14f74-5aa9-4693-8917-4bcfc3490840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making siteId an integer\n",
    "for zones in zones_data:\n",
    "    zones[\"siteId\"] = int(zones[\"siteId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1eff55-e325-40fa-b903-540207d94352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting into dataframe\n",
    "df_zones = pd.DataFrame(zones_data[\"siteId\"])  \n",
    "df_zones[\"geometry\"] = df_zones[\"polygon\"].apply(lambda x: Polygon(x)) \n",
    "\n",
    "#setting crs and geometry\n",
    "gdf_zones = gpd.GeoDataFrame(df_zones, geometry=\"geometry\")\n",
    "gdf_zones.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "#exploring the first few rows of data\n",
    "print(gdf_zones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8882bb19-8d61-4a7a-83ca-42d453c0fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing spatial joins using sjoin\n",
    "gdf_sensors_zones = gpd.sjoin(gdf_sensors, gdf_zones, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "#exploring the first few rows\n",
    "print(gdf_sensors_zones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6d733-cf9b-499c-8a0d-c5df1ccdb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting the sensors in every working zone\n",
    "sensor_counts = gdf_sensors_zones.groupby(\"zone_id\").size().reset_index(name=\"sensor_count\")\n",
    "\n",
    "#merging the counts into the working zone geodataframe\n",
    "gdf_zones = gdf_zones.merge(sensor_counts, on=\"zone_id\", how=\"left\")\n",
    "\n",
    "#getting rid of non values\n",
    "gdf_zones[\"sensor_count\"] = gdf_zones[\"sensor_count\"].dropna()\n",
    "\n",
    "print(gdf_zones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c41d7-03ab-404f-b9a8-14adc6974e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the chloropleth map using leafmap\n",
    "import leafmap\n",
    "\n",
    "m = leafmap.Map(\n",
    "    center=(56.329031,-3.798943),\n",
    "    zoom=7\n",
    ")\n",
    "\n",
    "m.add_basemap(\"CartoDB.Positron\")\n",
    "\n",
    "m.add_data(\n",
    "    gdf_zones,\n",
    "    column=\"sensor_count\",\n",
    "    legend_title=\"Sensor Count\",\n",
    "    cmap=\"OrRd\",  # Red color gradient (adjust if needed)\n",
    "    k=5,  # Number of color bins\n",
    ")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c5393-7827-4181-98f3-a7eecc657d7d",
   "metadata": {},
   "source": [
    "## Reading a WMS Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca57483-18de-4a73-a3d1-889f16831023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leafmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4621263f-849d-41bd-aef9-a870a6fd8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = leafmap.Map(\n",
    "    center=(56.329031,-3.798943),\n",
    "    zoom=7\n",
    ")\n",
    "wms_url = 'https://maps.gov.scot/server/services/NRS/Census2011/MapServer/WMSServer?'\n",
    "# A WMS URL include multiple layers, so you need to provide the name you need to load in your map.\n",
    "# See this: https://www.spatialdata.gov.scot/geonetwork/srv/eng/catalog.search#/metadata/ff882746-e913-4f78-862e-f6e3974fb80e\n",
    "\n",
    "\n",
    "m.add_wms_layer(url=wms_url, layers='WorkplaceZones2011', name='Census2011', shown=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf8be4f-b7f3-4dac-83ff-aee96f3b9d14",
   "metadata": {},
   "source": [
    "# Finishing the Lab\n",
    "\n",
    "Make sure you save all your code and upload the latest version of this notebook in your GitHub Repo. If you havent created a Repo to store all your Jupyter Notebooks related to the Labs, make sure you create a well and organized GitHub repo where you have the most curated and finished notebooks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
